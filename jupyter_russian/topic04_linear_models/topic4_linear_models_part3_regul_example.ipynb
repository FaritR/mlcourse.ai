{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "</center>\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейные модели классификации и регрессии\n",
    "## <center>Часть 3. Наглядный пример регуляризации логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В 1 статье уже приводился пример того, как полиномиальные признаки позволяют линейным моделям строить нелинейные разделяющие поверхности. Покажем это в картинках.\n",
    "\n",
    "Посмотрим, как регуляризация влияет на качество классификации на наборе данных по тестированию микрочипов из курса Andrew Ng по машинному обучению. \n",
    "Будем использовать логистическую регрессию с полиномиальными признаками и варьировать параметр регуляризации C.\n",
    "Сначала посмотрим, как регуляризация влияет на разделяющую границу классификатора, интуитивно распознаем переобучение и недообучение.\n",
    "Потом численно установим близкий к оптимальному параметр регуляризации с помощью кросс-валидации (`cross-validation`) и  перебора по сетке (`GridSearch`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные с помощью метода `read_csv` библиотеки `pandas`. В этом наборе данных для 118 микрочипов (объекты) указаны результаты двух тестов по контролю качества (два числовых признака) и сказано, пустили ли микрочип в производство. Признаки уже центрированы, то есть из всех значений вычтены средние по столбцам. Таким образом, \"среднему\" микрочипу соответствуют нулевые значения результатов тестов.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   test1     118 non-null    float64\n",
      " 1   test2     118 non-null    float64\n",
      " 2   released  118 non-null    int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 2.9 KB\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "data = pd.read_csv(\n",
    "    \"../../data/microchip_tests.txt\", header=None, names=(\"test1\", \"test2\", \"released\")\n",
    ")\n",
    "# информация о наборе данных\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на первые и последние 5 строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test2</th>\n",
       "      <th>released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051267</td>\n",
       "      <td>0.69956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.092742</td>\n",
       "      <td>0.68494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.213710</td>\n",
       "      <td>0.69225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.50219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513250</td>\n",
       "      <td>0.46564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test1    test2  released\n",
       "0  0.051267  0.69956         1\n",
       "1 -0.092742  0.68494         1\n",
       "2 -0.213710  0.69225         1\n",
       "3 -0.375000  0.50219         1\n",
       "4 -0.513250  0.46564         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним обучающую выборку и метки целевого класса в отдельных массивах NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :2].values\n",
    "y = data.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.051267 ,  0.69956  ],\n",
       "       [-0.092742 ,  0.68494  ],\n",
       "       [-0.21371  ,  0.69225  ],\n",
       "       [-0.375    ,  0.50219  ],\n",
       "       [-0.51325  ,  0.46564  ],\n",
       "       [-0.52477  ,  0.2098   ],\n",
       "       [-0.39804  ,  0.034357 ],\n",
       "       [-0.30588  , -0.19225  ],\n",
       "       [ 0.016705 , -0.40424  ],\n",
       "       [ 0.13191  , -0.51389  ],\n",
       "       [ 0.38537  , -0.56506  ],\n",
       "       [ 0.52938  , -0.5212   ],\n",
       "       [ 0.63882  , -0.24342  ],\n",
       "       [ 0.73675  , -0.18494  ],\n",
       "       [ 0.54666  ,  0.48757  ],\n",
       "       [ 0.322    ,  0.5826   ],\n",
       "       [ 0.16647  ,  0.53874  ],\n",
       "       [-0.046659 ,  0.81652  ],\n",
       "       [-0.17339  ,  0.69956  ],\n",
       "       [-0.47869  ,  0.63377  ],\n",
       "       [-0.60541  ,  0.59722  ],\n",
       "       [-0.62846  ,  0.33406  ],\n",
       "       [-0.59389  ,  0.005117 ],\n",
       "       [-0.42108  , -0.27266  ],\n",
       "       [-0.11578  , -0.39693  ],\n",
       "       [ 0.20104  , -0.60161  ],\n",
       "       [ 0.46601  , -0.53582  ],\n",
       "       [ 0.67339  , -0.53582  ],\n",
       "       [-0.13882  ,  0.54605  ],\n",
       "       [-0.29435  ,  0.77997  ],\n",
       "       [-0.26555  ,  0.96272  ],\n",
       "       [-0.16187  ,  0.8019   ],\n",
       "       [-0.17339  ,  0.64839  ],\n",
       "       [-0.28283  ,  0.47295  ],\n",
       "       [-0.36348  ,  0.31213  ],\n",
       "       [-0.30012  ,  0.027047 ],\n",
       "       [-0.23675  , -0.21418  ],\n",
       "       [-0.06394  , -0.18494  ],\n",
       "       [ 0.062788 , -0.16301  ],\n",
       "       [ 0.22984  , -0.41155  ],\n",
       "       [ 0.2932   , -0.2288   ],\n",
       "       [ 0.48329  , -0.18494  ],\n",
       "       [ 0.64459  , -0.14108  ],\n",
       "       [ 0.46025  ,  0.012427 ],\n",
       "       [ 0.6273   ,  0.15863  ],\n",
       "       [ 0.57546  ,  0.26827  ],\n",
       "       [ 0.72523  ,  0.44371  ],\n",
       "       [ 0.22408  ,  0.52412  ],\n",
       "       [ 0.44297  ,  0.67032  ],\n",
       "       [ 0.322    ,  0.69225  ],\n",
       "       [ 0.13767  ,  0.57529  ],\n",
       "       [-0.0063364,  0.39985  ],\n",
       "       [-0.092742 ,  0.55336  ],\n",
       "       [-0.20795  ,  0.35599  ],\n",
       "       [-0.20795  ,  0.17325  ],\n",
       "       [-0.43836  ,  0.21711  ],\n",
       "       [-0.21947  , -0.016813 ],\n",
       "       [-0.13882  , -0.27266  ],\n",
       "       [ 0.18376  ,  0.93348  ],\n",
       "       [ 0.22408  ,  0.77997  ],\n",
       "       [ 0.29896  ,  0.61915  ],\n",
       "       [ 0.50634  ,  0.75804  ],\n",
       "       [ 0.61578  ,  0.7288   ],\n",
       "       [ 0.60426  ,  0.59722  ],\n",
       "       [ 0.76555  ,  0.50219  ],\n",
       "       [ 0.92684  ,  0.3633   ],\n",
       "       [ 0.82316  ,  0.27558  ],\n",
       "       [ 0.96141  ,  0.085526 ],\n",
       "       [ 0.93836  ,  0.012427 ],\n",
       "       [ 0.86348  , -0.082602 ],\n",
       "       [ 0.89804  , -0.20687  ],\n",
       "       [ 0.85196  , -0.36769  ],\n",
       "       [ 0.82892  , -0.5212   ],\n",
       "       [ 0.79435  , -0.55775  ],\n",
       "       [ 0.59274  , -0.7405   ],\n",
       "       [ 0.51786  , -0.5943   ],\n",
       "       [ 0.46601  , -0.41886  ],\n",
       "       [ 0.35081  , -0.57968  ],\n",
       "       [ 0.28744  , -0.76974  ],\n",
       "       [ 0.085829 , -0.75512  ],\n",
       "       [ 0.14919  , -0.57968  ],\n",
       "       [-0.13306  , -0.4481   ],\n",
       "       [-0.40956  , -0.41155  ],\n",
       "       [-0.39228  , -0.25804  ],\n",
       "       [-0.74366  , -0.25804  ],\n",
       "       [-0.69758  ,  0.041667 ],\n",
       "       [-0.75518  ,  0.2902   ],\n",
       "       [-0.69758  ,  0.68494  ],\n",
       "       [-0.4038   ,  0.70687  ],\n",
       "       [-0.38076  ,  0.91886  ],\n",
       "       [-0.50749  ,  0.90424  ],\n",
       "       [-0.54781  ,  0.70687  ],\n",
       "       [ 0.10311  ,  0.77997  ],\n",
       "       [ 0.057028 ,  0.91886  ],\n",
       "       [-0.10426  ,  0.99196  ],\n",
       "       [-0.081221 ,  1.1089   ],\n",
       "       [ 0.28744  ,  1.087    ],\n",
       "       [ 0.39689  ,  0.82383  ],\n",
       "       [ 0.63882  ,  0.88962  ],\n",
       "       [ 0.82316  ,  0.66301  ],\n",
       "       [ 0.67339  ,  0.64108  ],\n",
       "       [ 1.0709   ,  0.10015  ],\n",
       "       [-0.046659 , -0.57968  ],\n",
       "       [-0.23675  , -0.63816  ],\n",
       "       [-0.15035  , -0.36769  ],\n",
       "       [-0.49021  , -0.3019   ],\n",
       "       [-0.46717  , -0.13377  ],\n",
       "       [-0.28859  , -0.060673 ],\n",
       "       [-0.61118  , -0.067982 ],\n",
       "       [-0.66302  , -0.21418  ],\n",
       "       [-0.59965  , -0.41886  ],\n",
       "       [-0.72638  , -0.082602 ],\n",
       "       [-0.83007  ,  0.31213  ],\n",
       "       [-0.72062  ,  0.53874  ],\n",
       "       [-0.59389  ,  0.49488  ],\n",
       "       [-0.48445  ,  0.99927  ],\n",
       "       [-0.0063364,  0.99927  ],\n",
       "       [ 0.63265  , -0.030612 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим данные. Красный цвет соответствует бракованным чипам, зеленый – нормальным.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c=\"green\", label=\"Выпущен\")\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c=\"red\", label=\"Бракован\")\n",
    "plt.xlabel(\"Тест 1\")\n",
    "plt.ylabel(\"Тест 2\")\n",
    "plt.title(\"2 теста микрочипов\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем функцию для отображения разделяющей кривой классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X, y, grid_step=0.01, poly_featurizer=None):\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, grid_step), np.arange(y_min, y_max, grid_step)\n",
    "    )\n",
    "\n",
    "    # каждой точке в сетке [x_min, m_max]x[y_min, y_max]\n",
    "    # ставим в соответствие свой цвет\n",
    "    Z = clf.predict(poly_featurizer.transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиномиальными признаками до степени $d$ для двух переменных $x_1$ и $x_2$ мы называем следующие:\n",
    "\n",
    "$$\\large \\{x_1^d, x_1^{d-1}x_2, \\ldots x_2^d\\} =  \\{x_1^ix_2^j\\}_{i+j=d, i,j \\in \\mathbb{N}}$$\n",
    "\n",
    "Например, для $d=3$ это будут следующие признаки:\n",
    "\n",
    "$$\\large 1, x_1, x_2,  x_1^2, x_1x_2, x_2^2, x_1^3, x_1^2x_2, x_1x_2^2, x_2^3$$\n",
    "\n",
    "Нарисовав треугольник Пифагора, Вы сообразите, сколько таких признаков будет для $d=4,5...$ и вообще для любого $d$.\n",
    "Попросту говоря, таких признаков экспоненциально много, и строить, скажем, для 100 признаков полиномиальные степени 10 может оказаться затратно (а более того, и не нужно). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим объект `sklearn`, который добавит в матрицу $X$ полиномиальные признаки вплоть до степени 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=7)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию с параметром регуляризации $C = 10^{-2}$. Изобразим разделяющую границу.\n",
    "Также проверим долю правильных ответов классификатора на обучающей выборке. Видим, что регуляризация оказалась \n",
    "слишком сильной, и модель \"недообучилась\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1e-2\n",
    "logit = LogisticRegression(C=C, n_jobs=-1, random_state=17)\n",
    "logit.fit(X_poly, y)\n",
    "\n",
    "plot_boundary(logit, X, y, grid_step=0.01, poly_featurizer=poly)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c=\"green\", label=\"Выпущен\")\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c=\"red\", label=\"Бракован\")\n",
    "plt.xlabel(\"Тест 1\")\n",
    "plt.ylabel(\"Тест 2\")\n",
    "plt.title(\"2 теста микрочипов. Логит с C=0.01\")\n",
    "plt.legend()\n",
    "\n",
    "print(\n",
    "    \"Доля правильных ответов классификатора на обучающей выборке:\",\n",
    "    round(logit.score(X_poly, y), 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим $C$ до 1. Тем самым мы *ослабляем* регуляризацию, теперь в решении значния весов логистической регрессии могут оказаться больше (по модулю), чем в прошлом случае. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "logit = LogisticRegression(C=C, n_jobs=-1, random_state=17)\n",
    "logit.fit(X_poly, y)\n",
    "\n",
    "plot_boundary(logit, X, y, grid_step=0.005, poly_featurizer=poly)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c=\"green\", label=\"Выпущен\")\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c=\"red\", label=\"Бракован\")\n",
    "plt.xlabel(\"Тест 1\")\n",
    "plt.ylabel(\"Тест 2\")\n",
    "plt.title(\"2 теста микрочипов. Логит с C=1\")\n",
    "plt.legend()\n",
    "\n",
    "print(\n",
    "    \"Доля правильных ответов классификатора на обучающей выборке:\",\n",
    "    round(logit.score(X_poly, y), 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще увеличим $C$ – до 10 тысяч. Теперь регуляризации явно недостаточно, и мы наблюдаем переобучение. Можно заметить, что в прошлом случае (при $C$=1 и \"гладкой\" границе) доля правильных ответов модели на обучающей выборке не намного ниже, чем в 3 случае, зато на новой выборке, можно себе представить, 2 модель сработает намного лучше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1e4\n",
    "logit = LogisticRegression(C=C, n_jobs=-1, random_state=17)\n",
    "logit.fit(X_poly, y)\n",
    "\n",
    "plot_boundary(logit, X, y, grid_step=0.005, poly_featurizer=poly)\n",
    "\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c=\"green\", label=\"Выпущен\")\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], c=\"red\", label=\"Бракован\")\n",
    "plt.xlabel(\"Тест 1\")\n",
    "plt.ylabel(\"Тест 2\")\n",
    "plt.title(\"2 теста микрочипов. Логит с C=10k\")\n",
    "plt.legend()\n",
    "\n",
    "print(\n",
    "    \"Доля правильных ответов классификатора на обучающей выборке:\",\n",
    "    round(logit.score(X_poly, y), 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтоб обсудить результаты, перепишем формулу для функционала, который оптимизируется в логистической регрессии, в таком виде:\n",
    "$$J(X,y,w) = \\mathcal{L} + \\frac{1}{C}||w||^2,$$\n",
    "\n",
    "где\n",
    " - $\\mathcal{L}$ – логистическая функция потерь, просуммированная по всей выборке\n",
    " - $C$ – обратный коэффициент регуляризации (тот самый $C$ в `sklearn`-реализации `LogisticRegression`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточные выводы**:\n",
    " - чем больше параметр $C$, тем более сложные зависимости в данных может восстанавливать модель (интуитивно $C$ соответствует \"сложности\" модели (model capacity))\n",
    " - если регуляризация слишком сильная (малые значения $C$), то решением задачи минимизации логистической функции потерь может оказаться то, когда многие веса занулились или стали слишком малыми. Еще говорят, что модель недостаточно \"штрафуется\" за ошибки (то есть в функционале $J$ \"перевешивает\" сумма квадратов весов, а ошибка $\\mathcal{L}$ может быть относительно большой). В таком случае модель окажется *недообученной* (1 случай)\n",
    " - наоборот, если регуляризация слишком слабая (большие значения $C$), то решением задачи оптимизации может стать вектор $w$ с большими по модулю  компонентами. В таком случае больший вклад в оптимизируемый функционал $J$ имеет  $\\mathcal{L}$ и, вольно выражаясь, модель слишком \"боится\" ошибиться на объектах обучающей выборки, поэтому окажется *переобученной* (3 случай)\n",
    " - то, какое значение $C$ выбрать, сама логистическая регрессия \"не поймет\" (или еще говорят \"не выучит\"), то есть это не может быть определено решением оптимизационной задачи, которой является логистическая регрессия (в отличие от весов $w$). Так же точно, дерево решений не может \"само понять\", какое ограничение на глубину выбрать (за один процесс обучения). Поэтому $C$ – это *гиперпараметр* модели, который настраивается на кросс-валидации, как и *max_depth* для дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Настройка параметра регуляризации**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем оптимальное (в данном примере) значение параметра регуляризации $C$. Сделать это можно с помощью `LogisticRegressionCV` – перебора параметров по сетке с последующей кросс-валидацией. Этот класс создан специально для логистической регрессии (для нее известны эффективные алгоритмы перебора параметров), для произвольной модели мы бы использовали `GridSearchCV`, `RandomizedSearchCV` или, например, специальные алгоритмы оптимизации гиперпараметров, реализованные в `hyperopt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "c_values = np.logspace(-2, 3, 500)\n",
    "\n",
    "logit_searcher = LogisticRegressionCV(Cs=c_values, cv=skf, verbose=1, n_jobs=-1)\n",
    "logit_searcher.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_searcher.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как качество модели (доля правильных ответов на обучающей и валидационной выборках) меняется при изменении гиперпараметра $C$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean CV-accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим участок с \"лучшими\" значениями C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_values, np.mean(logit_searcher.scores_[1], axis=0))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean CV-accuracy\")\n",
    "plt.xlim((0, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такие кривые называются *валидационными*, и в `sklearn` для них их построения есть специальные методы."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
